{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import log\n",
    "from matplotlib import pyplot as plt \n",
    "from scipy.integrate import odeint  # 微分用\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 確保項目根目錄在模組路徑中\n",
    "project_root = os.path.abspath(\"COVID-19-TIME-SERIES-PREDICT\")  # 替換為你的根目錄路徑\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# 導入自編模組\n",
    "from utils.common_tools import *\n",
    "\n",
    "# pandas跟NUMPY設定\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AFG' 'OWID_AFR' 'ALB' 'DZA' 'AND' 'AGO' 'AIA' 'ATG' 'ARG' 'ARM' 'ABW'\n",
      " 'OWID_ASI' 'AUS' 'AUT' 'AZE' 'BHS' 'BHR' 'BGD' 'BRB' 'BLR' 'BEL' 'BLZ'\n",
      " 'BEN' 'BMU' 'BTN' 'BOL' 'BES' 'BIH' 'BWA' 'BRA' 'VGB' 'BRN' 'BGR' 'BFA'\n",
      " 'BDI' 'KHM' 'CMR' 'CAN' 'CPV' 'CYM' 'CAF' 'TCD' 'CHL' 'CHN' 'COL' 'COM'\n",
      " 'COG' 'COK' 'CRI' 'CIV' 'HRV' 'CUB' 'CUW' 'CYP' 'CZE' 'COD' 'DNK' 'DJI'\n",
      " 'DMA' 'DOM' 'ECU' 'EGY' 'SLV' 'GNQ' 'ERI' 'EST' 'SWZ' 'ETH' 'OWID_EUR'\n",
      " 'OWID_EUN' 'FRO' 'FLK' 'FJI' 'FIN' 'FRA' 'PYF' 'GAB' 'GMB' 'GEO' 'DEU'\n",
      " 'GHA' 'GIB' 'GRC' 'GRL' 'GRD' 'GTM' 'GGY' 'GIN' 'GNB' 'GUY' 'HTI'\n",
      " 'OWID_HIC' 'HND' 'HKG' 'HUN' 'ISL' 'IND' 'IDN' 'OWID_INT' 'IRN' 'IRQ'\n",
      " 'IRL' 'IMN' 'ISR' 'ITA' 'JAM' 'JPN' 'JEY' 'JOR' 'KAZ' 'KEN' 'KIR'\n",
      " 'OWID_KOS' 'KWT' 'KGZ' 'LAO' 'LVA' 'LBN' 'LSO' 'LBR' 'LBY' 'LIE' 'LTU'\n",
      " 'OWID_LIC' 'OWID_LMC' 'LUX' 'MAC' 'MDG' 'MWI' 'MYS' 'MDV' 'MLI' 'MLT'\n",
      " 'MHL' 'MRT' 'MUS' 'MEX' 'FSM' 'MDA' 'MCO' 'MNG' 'MNE' 'MSR' 'MAR' 'MOZ'\n",
      " 'MMR' 'NAM' 'NRU' 'NPL' 'NLD' 'NCL' 'NZL' 'NIC' 'NER' 'NGA' 'NIU'\n",
      " 'OWID_NAM' 'MKD' 'OWID_CYN' 'NOR' 'OWID_OCE' 'OMN' 'PAK' 'PLW' 'PSE'\n",
      " 'PAN' 'PNG' 'PRY' 'PER' 'PHL' 'PCN' 'POL' 'PRT' 'QAT' 'ROU' 'RUS' 'RWA'\n",
      " 'SHN' 'KNA' 'LCA' 'SPM' 'VCT' 'WSM' 'SMR' 'STP' 'SAU' 'SEN' 'SRB' 'SYC'\n",
      " 'SLE' 'SGP' 'SXM' 'SVK' 'SVN' 'SLB' 'SOM' 'ZAF' 'OWID_SAM' 'KOR' 'SSD'\n",
      " 'ESP' 'LKA' 'SDN' 'SUR' 'SWE' 'CHE' 'SYR' 'TWN' 'TJK' 'TZA' 'THA' 'TLS'\n",
      " 'TGO' 'TKL' 'TON' 'TTO' 'TUN' 'TUR' 'TKM' 'TCA' 'TUV' 'UGA' 'UKR' 'ARE'\n",
      " 'GBR' 'USA' 'OWID_UMC' 'URY' 'UZB' 'VUT' 'VAT' 'VEN' 'VNM' 'WLF'\n",
      " 'OWID_WRL' 'YEM' 'ZMB' 'ZWE']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-02-24         5.00       5.00   \n",
       "1      AFG      Asia  Afghanistan  2020-02-25         5.00       0.00   \n",
       "2      AFG      Asia  Afghanistan  2020-02-26         5.00       0.00   \n",
       "3      AFG      Asia  Afghanistan  2020-02-27         5.00       0.00   \n",
       "4      AFG      Asia  Afghanistan  2020-02-28         5.00       0.00   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "1                 NaN           NaN         NaN                  NaN  ...   \n",
       "2                 NaN           NaN         NaN                  NaN  ...   \n",
       "3                 NaN           NaN         NaN                  NaN  ...   \n",
       "4                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                   37.75   \n",
       "1             NaN           NaN                   37.75   \n",
       "2             NaN           NaN                   37.75   \n",
       "3             NaN           NaN                   37.75   \n",
       "4             NaN           NaN                   37.75   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                        0.50            64.83                     0.51   \n",
       "1                        0.50            64.83                     0.51   \n",
       "2                        0.50            64.83                     0.51   \n",
       "3                        0.50            64.83                     0.51   \n",
       "4                        0.50            64.83                     0.51   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "1               NaN                                      NaN  \n",
       "2               NaN                                      NaN  \n",
       "3               NaN                                      NaN  \n",
       "4               NaN                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_covid_data()  # -> pd.DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  total_cases  new_cases  new_cases_smoothed  new_deaths  \\\n",
       "0  2020-02-24         5.00       5.00                 NaN         NaN   \n",
       "1  2020-02-25         5.00       0.00                 NaN         NaN   \n",
       "2  2020-02-26         5.00       0.00                 NaN         NaN   \n",
       "3  2020-02-27         5.00       0.00                 NaN         NaN   \n",
       "4  2020-02-28         5.00       0.00                 NaN         NaN   \n",
       "\n",
       "   population  \n",
       "0 39835428.00  \n",
       "1 39835428.00  \n",
       "2 39835428.00  \n",
       "3 39835428.00  \n",
       "4 39835428.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = extract_SIR_target_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we've got functions here\n",
    "\n",
    "def dYdt(Y, t, N, beta, gamma) -> list:\n",
    "    # 三條函式\n",
    "    # the t argument in the deriv function is technically not redundant, even though it is not directly used in the function\n",
    "    '''\n",
    "    Calculate the changing of the three subgroups.\n",
    "    A: S, I, R\n",
    "    t: time\n",
    "    beta: tesla(average persons interacted) * c(infectious rate)\n",
    "    gamma: recovery rate (=1/d)\n",
    "    N: total population, assumed S+I+R = N\n",
    "    '''\n",
    "    S, I, R = Y\n",
    "    dSdt = -(beta)*(I)*(S) / N\n",
    "    dIdt = (beta)*(I)*(S) / N - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt\n",
    "\n",
    "'''INITIAL STATUS: A = [N - I0, I0, 0]'''\n",
    "\n",
    "def calculate_mape(true_values, predictions):\n",
    "        \"\"\"\n",
    "        計算 Mean Absolute Percentage Error (MAPE)\n",
    "        \"\"\"\n",
    "        true_values = np.array(true_values)\n",
    "        predictions = np.array(predictions)\n",
    "        return np.mean(np.abs((true_values - predictions) / true_values)) * 100\n",
    "\n",
    "def calculate_ppe(true_values, predictions):\n",
    "    \"\"\"\n",
    "    計算 Peak Prediction Error (PPE)\n",
    "    \"\"\"\n",
    "    peak_true_value = np.max(true_values)\n",
    "    peak_true_time = np.argmax(true_values)\n",
    "\n",
    "    peak_pred_value = np.max(predictions)\n",
    "    peak_pred_time = np.argmax(predictions)\n",
    "\n",
    "    value_error = np.abs(peak_true_value - peak_pred_value)\n",
    "    time_error = np.abs(peak_true_time - peak_pred_time)\n",
    "\n",
    "    return value_error, time_error\n",
    "\n",
    "\n",
    "def log_transform(data: pd.DataFrame, column: str):\n",
    "    data[\"log_\" + column] = log(data[column] + 0.01)\n",
    "    return data\n",
    "\n",
    "def adf_test(data: pd.DataFrame, column: str):\n",
    "    data.dropna(inplace=True)\n",
    "    result = adfuller(data[column])\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if result[1] < 0.05:\n",
    "        print(\"數據是穩態的\")\n",
    "    else:\n",
    "        print(\"數據是非穩態的，需要進行差分\")\n",
    "\n",
    "    # 3. 繪製 ACF 和 PACF 檢查自相關性\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_acf(data[\"new_cases\"], lags=30, ax=plt.subplot(121))\n",
    "    plot_pacf(data[\"new_cases\"], lags=30, ax=plt.subplot(122))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def grid_search_ARIMA(data: pd.DataFrame, column: str):\n",
    "    best_model = None\n",
    "    best_order = None\n",
    "    best_aic = float(\"inf\")\n",
    "\n",
    "    for p in range(3):\n",
    "        for d in range(3):\n",
    "            for q in range(3):\n",
    "                try:\n",
    "                    model = ARIMA(data[column], order=(p, d, q))\n",
    "                    model_fit = model.fit()\n",
    "\n",
    "                    if model_fit.aic < best_aic:\n",
    "                        best_model = model_fit\n",
    "                        best_order = (p, d, q)\n",
    "                        best_aic = model_fit.aic\n",
    "                except Exception as e:\n",
    "                    # 捕捉錯誤，但繼續進行其他組合的測試\n",
    "                    print(f\"Error for order ({p}, {d}, {q}): {e}\")\n",
    "                    continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"Best Model Summary:\")\n",
    "        print(best_model.summary())\n",
    "    else:\n",
    "        print(\"No suitable model found.\")\n",
    "\n",
    "    return best_order\n",
    "\n",
    "def rolling_forecast(data: pd.DataFrame, column: str, best_order: tuple):\n",
    "    # 劃分數據集\n",
    "    train_size = int(len(data) * 0.8 // 1)  # 使用前 80% 的數據作為訓練集\n",
    "    train = data.iloc[:train_size]     # 訓練集\n",
    "    test = data.iloc[train_size:]      # 測試集\n",
    "\n",
    "    print(f\"Train Size: {len(train)}, Test Size: {len(test)}\")\n",
    "\n",
    "    # 初始化滾動預測\n",
    "    history = [x for x in train[column]]  # 使用訓練集的初始數據\n",
    "    predictions = []  # 儲存每次的預測結果\n",
    "\n",
    "    # 滾動預測\n",
    "    for t in range(len(test)):\n",
    "        # 構建並擬合 ARIMA 模型\n",
    "        model = ARIMA(history, order=best_order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # 預測下一個時間點\n",
    "        yhat = model_fit.forecast(steps=1)[0]\n",
    "        predictions.append(yhat)\n",
    "\n",
    "        # 將真實值加入訓練集\n",
    "        history.append(test[column].iloc[t])\n",
    "\n",
    "    # 計算各種指標\n",
    "    mae = mean_absolute_error(test[column], predictions)\n",
    "    r2 = r2_score(test[column], predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(test[column], predictions))\n",
    "\n",
    "    print(f\"Mean of Real Data: {np.mean(test[column])}\")\n",
    "    print(f\"Median of Real Data: {np.median(test[column])}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\") # 平均絕對誤差\n",
    "    print(f\"Percentage of MAE: {mae / np.mean(test[column])}\") # 平均絕對誤差占比\n",
    "    print(f\"Rolling Forecast RMSE: {rmse}\") # RMSE\n",
    "\n",
    "def check_residuals(data: pd.DataFrame, column: str, best_order: tuple):\n",
    "    # 檢查殘差的自相關性\n",
    "    model = ARIMA(data[column], order=best_order)\n",
    "    model_fit = model.fit()\n",
    "    residuals = model_fit.resid\n",
    "    lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)\n",
    "    print(lb_test)\n",
    "\n",
    "    # 檢查殘差的正態分佈\n",
    "    stat, p = normaltest(residuals)\n",
    "    print(f\"Normality Test: Statistic={stat}, p={p}\")\n",
    "    if p > 0.05:\n",
    "        print(\"殘差接近正態分佈\")\n",
    "    else:\n",
    "        print(\"殘差偏離正態分佈\")\n",
    "\n",
    "def multi_step_forecast(data: pd.DataFrame, column: str, best_order: tuple, forecast_steps: int):\n",
    "    # 劃分數據集\n",
    "    train_size = int(len(data) * 0.8 // 1)  # 使用前 80% 的數據作為訓練集\n",
    "    train = data.iloc[:train_size]     # 訓練集\n",
    "    test = data.iloc[train_size:]      # 測試集\n",
    "    \n",
    "    \n",
    "    model = ARIMA(data[column], order=best_order)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    forecast = model_fit.forecast(steps=forecast_steps)\n",
    "\n",
    "    # 比較真實值與預測值\n",
    "    real_values = test[\"new_cases\"].iloc[:forecast_steps]\n",
    "    rmse = np.sqrt(mean_squared_error(real_values, forecast))\n",
    "    print(f\"Multi-step Forecast RMSE: {rmse}\")\n",
    "\n",
    "def pipeline(data: pd.DataFrame, column: str, forecast_steps: int):\n",
    "    data = log_transform(data, column)\n",
    "    adf_test(data, \"log_\" + column)\n",
    "    print(\"----------------Gird Search ARIMA------------------\")\n",
    "    best_order = grid_search_ARIMA(data, \"log_\" + column)\n",
    "    print(\"----------------Rolling Forecast------------------\")\n",
    "    rolling_forecast(data, \"log_\" + column, best_order)\n",
    "    print(\"----------------Check Residuals------------------\")\n",
    "    check_residuals(data, \"log_\" + column, best_order)\n",
    "    print(\"----------------Multi-step Forecast------------------\")\n",
    "    multi_step_forecast(data, \"log_\" + column, best_order, forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基礎SIR模型測試，採用BETA = 0.15\n",
    "\n",
    "\n",
    "# initialising\n",
    "gamma = 1/10  # assuming that recovering days are 10 days\n",
    "cutting_point = 0.5\n",
    "split_index = int(len(data) * cutting_point)\n",
    "training_data = data.iloc[:split_index]\n",
    "training_data = training_data.fillna(0) # 去空值\n",
    "\n",
    "population = int(training_data.iloc[0]['population'])\n",
    "initial_cases = int(training_data.iloc[0]['total_cases'])\n",
    "S0 = int(population - initial_cases)\n",
    "I0 = int(initial_cases)\n",
    "R0 = 0\n",
    "y0 = (S0, I0, R0)\n",
    "\n",
    "training_data['date'] = pd.to_datetime(training_data['date'])\n",
    "t = (training_data['date'] - training_data['date'].iloc[0]).dt.days  # Calculate the numeric time points (days since the first date)\n",
    "\n",
    "beta = 0.15  # 後用rolling求\n",
    "S_I_R_series = odeint(dYdt, y0, t, args=(population, beta, gamma))\n",
    "# ordinary differential equation integration; odeint的三個arguments: 方程式、Y、Xi\n",
    "# t is a numeric series, which is necessary for odeint\n",
    "S, I, R = S_I_R_series.T\n",
    "\n",
    "print(S_I_R_series)\n",
    "\n",
    "fig = plt.figure(facecolor='w')\n",
    "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
    "ax.grid(visible=True, which='major', c='w', lw=2, ls='-')\n",
    "ax.plot(t, S/1000, 'b', alpha=0.5, lw=2, label='Susceptible')\n",
    "ax.plot(t, I/1000, 'r', alpha=0.5, lw=2, label='Infected')\n",
    "ax.plot(t, R/1000, 'g', alpha=0.5, lw=2, label='Recovered or Removed')\n",
    "ax.set_xlabel('Time /days')\n",
    "ax.set_ylabel('Number (1000s)')\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "legend = ax.legend()\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "for spine in ('top', 'right', 'bottom', 'left'):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# find_best_suiting_beta(y0, t_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_suiting_beta(y0, t: pd.Series, population):\n",
    "    '''Y0為S,I,R之初始狀態；t為尋找beta使用的區間'''\n",
    "    # 模型指標看mae mae/mean rmse 三個\n",
    "    # 以前80%的資料，以「用I對比真實累積確診人數」方式，尋找最佳beta\n",
    "    # 設0.1<=beta<=0.9 \n",
    "    # mean_absolute_error()\n",
    "    # 全用global變數\n",
    "    \n",
    "    lowest_MAE = 9999999999\n",
    "    fittest_beta = 0\n",
    "    for beta in list(map(lambda x: x/10, range(0,10))):\n",
    "        S_I_R_series = odeint(dYdt, y0, t, args=(population, beta, gamma))\n",
    "        I = S_I_R_series.T[2]\n",
    "        I += y0[1]  # 需要把R加回去 才會是總確診人數\n",
    "        MAE = mean_absolute_error(I, data['total_cases'].iloc[int(t.iloc[0]):int(t.iloc[-1]+1)])  # 讓I跟相同區間的真實資料(總確診人數)比較\n",
    "\n",
    "        if MAE < lowest_MAE:\n",
    "            lowest_MAE = MAE\n",
    "            fittest_beta = beta\n",
    "\n",
    "    for beta in list(map(lambda x: x/100, range(int(fittest_beta*100 - 5), int(fittest_beta*100 + 6), 1))):\n",
    "        S_I_R_series = odeint(dYdt, y0, t, args=(population, beta, gamma))\n",
    "        I = S_I_R_series.T[2]\n",
    "        I += y0[1]  # 需要把R加回去 才會是總確診人數\n",
    "        MAE = mean_absolute_error(I, data['total_cases'].iloc[int(t.iloc[0]):int(t.iloc[-1]+1)])  # 讓I跟相同區間的真實資料(總確診人數)比較\n",
    "\n",
    "        if MAE < lowest_MAE:\n",
    "            lowest_MAE = MAE\n",
    "            fittest_beta = beta\n",
    "\n",
    "    for beta in list(map(lambda x: x/1000, range(int(fittest_beta*1000 - 9), int(fittest_beta*1000 + 9), 1))):\n",
    "        S_I_R_series = odeint(dYdt, y0, t, args=(population, beta, gamma))\n",
    "        I = S_I_R_series.T[2]\n",
    "        I += y0[1]  # 需要把R加回去 才會是總確診人數\n",
    "        MAE = mean_absolute_error(I, data['total_cases'].iloc[int(t.iloc[0]):int(t.iloc[-1]+1)])  # 讓I跟相同區間的真實資料(總確診人數)比較\n",
    "        I = pd.Series(I)  # print(I.head()), print(I.tail())\n",
    "\n",
    "        if MAE < lowest_MAE:\n",
    "            lowest_MAE = MAE\n",
    "            fittest_beta = beta\n",
    "\n",
    "    return fittest_beta, lowest_MAE\n",
    "\n",
    "# finding the most suiting beta by trying different betas and also comparing the MAEs\n",
    "# find_best_suiting_beta(y0, t) # return (fittest_beta, lowest_MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用  Our world in Data 上的 COVID-19 資料集*，目標預測每日新確診人數  (new_cases)\n",
    "使用 Rolling Window 方式進行資料切分，以前 28  天預測未來 7 天，每次向前平移 7 天\n",
    "\n",
    "每天使用模型預測後續疫情走向時，都會用當日以前的歷史資料去為當日建置對應的參數：\n",
    "1.\n",
    "每日都會有一個新的SIR Model (即給予)，傳統SIR Model從D0~Dn的beta都是固定的\n",
    "我們用過去28日的歷史資料算出一個最佳的beta，將當日的S,I,R與算出的beta代入，去預測未來七天的S,I,R\n",
    "\n",
    "2.建置一個每日beta值都會浮動的SIR模型，去讓從t0開始的模型更貼近真實疫情的走向，\n",
    "t0~t27日子都會有一個對應的beta值(傳染率)，t28~34則是：預測完t28 -> 將t28預測資料代入計算t28的beta -> 預測t29...\n",
    "\n",
    "我們先以方法1為準，由於訓練資料缺少Recovered/Removed的資料欄，故假設染病後10天復原/死亡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_rolling_prediction_by_SIR_and_calculate_indicators(data, print_out_details=False, print_out_prediction_array=False):\n",
    "    # 方法1，得到依資料滾動的beta，每個beta都是用過去28天資料去算出的最佳解（至小數第三位）\n",
    "\n",
    "    # initialising\n",
    "    population = int(data.iloc[0]['population'])\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    t = (data['date'] - data['date'].iloc[0]).dt.days\n",
    "    rolling_screen_range = 28  # 整個日期區間為28日\n",
    "    new_cases_prediction_array = np.array([])  # 每次計算七天份，全部放進這個ARRAY跟真實的new cases比較\n",
    "\n",
    "    for i in range(rolling_screen_range-1, len(data), 7):  # 假使i為第幾天，從第28天開始每天用前28天資料預測出的最佳beta\n",
    "        start_day = i - (rolling_screen_range-1)  # i指的是歷史資料區間結束日，start_day才是歷史資料區間開始日，相差27天意味整個日期區間為28日\n",
    "        if start_day < 0: start_day = 0\n",
    "        t_interval = t.iloc[start_day:i+1]  # i指的是區間結束日，slicing + 1\n",
    "\n",
    "        # 算出start_day(t0)的各項參數S,I,R，再用這個去算最貼近過去28天真實資料的beta\n",
    "        day_cases_before_date_all_recovered = start_day - int(1/gamma)  # Hypo: start_day 10 (即1/gamma) 天前的確診人一定全復原了（簡化模型）\n",
    "        if day_cases_before_date_all_recovered < 0: day_cases_before_date_all_recovered = 0\n",
    "        '''若是1/gamma > start_day 的情況，舉例start_day = 2, 1/gamma = 10\n",
    "        當始與終為(2,29)，假設T0 (即2日)時，第0日感染的人已經復原的比例為： data['total_cases'].iloc[0] * (1/10) * (2-0)，第1日感染的人已經復原的比例為： data['total_cases'].iloc[1] * (1/10) * (2-1)\n",
    "        故遞迴公式設為： data['total_cases'].iloc[j] * gamma * (start_day-j)'''\n",
    "\n",
    "        Rt0 = 0\n",
    "        for j in range(day_cases_before_date_all_recovered, start_day):\n",
    "            if (j <= day_cases_before_date_all_recovered): Rt0 += data['total_cases'].iloc[j] * gamma * (start_day-j)\n",
    "            else: Rt0 += (data['total_cases'].iloc[j] - data['total_cases'].iloc[j-1]) * gamma * (start_day-j)  # 第j日感染人數=total case(j) - total_case(j-1)\n",
    "        Rt0 = int(Rt0)\n",
    "        It0 = int(data['total_cases'].iloc[start_day] - Rt0)\n",
    "        St0 = int(population - It0 - Rt0)\n",
    "        yt0 = (St0, It0, Rt0)\n",
    "        \n",
    "        # 用過去28天真實資料算出最好的beta\n",
    "        fittest_beta, fittest_beta_MAE = find_best_suiting_beta(yt0, t_interval, population)\n",
    "        S_I_R_series = odeint(dYdt, yt0, t_interval, args=(population, fittest_beta, gamma))  # 用fittest beta去算的\n",
    "        S, I, R = S_I_R_series.T\n",
    "        I += Rt0\n",
    "\n",
    "        if (print_out_details == True):\n",
    "            print('\\nThis is day: ' + str(i))\n",
    "            print('使用歷史資料之起始日與結束日（<=28天）：', t_interval.iloc[0], t_interval.iloc[-1])\n",
    "            print('歷史資料起始日的 (S,I,R) =', yt0)\n",
    "            # print('從歷史資料起始日至截止日 該beta算出的TOTAL_CASES: ', I)\n",
    "            print('fittest_beta:', fittest_beta, '\\nfittest_beta_MAE', fittest_beta_MAE)\n",
    "\n",
    "        # 計算接下來七天的new cases (相當於dIdt)，先算ti時 S,I,R的狀態\n",
    "        day_cases_before_date_all_recovered = i - int(1/gamma)  # Hypo: i - 10 (即1/gamma) 天前的確診人一定全復原了（簡化模型）\n",
    "        if day_cases_before_date_all_recovered < 0: day_cases_before_date_all_recovered = 0\n",
    "        Rti = 0\n",
    "        for j in range(day_cases_before_date_all_recovered, i):\n",
    "            if (j <= day_cases_before_date_all_recovered): Rti += data['total_cases'].iloc[j] * gamma * (i-j)\n",
    "            else: Rti += (data['total_cases'].iloc[j] - data['total_cases'].iloc[j-1]) * gamma * (i-j)  # 第j日感染人數=total case(j) - total_case(j-1)\n",
    "        Rti = int(Rti)\n",
    "        Iti = int(data['total_cases'].iloc[i] - Rti)\n",
    "        Sti = int(population - Iti - Rti)\n",
    "        yti = (Sti, Iti, Rti)  \n",
    "        ytk = yti  # 初始狀態\n",
    "\n",
    "        # 計算接下來七天的new cases (並不相當於dIdt，其為dSdt，亦為dIdt的前項)\n",
    "        new_cases_prediction_array_7days = []\n",
    "        for k in range(i, i+7):\n",
    "            dSdt, dIdt, dRdt = dYdt(ytk, list(range(i, i+7)), population, fittest_beta, gamma)\n",
    "            new_cases_prediction_array_7days.append(-dSdt)  # -dSdt = (beta)*(I)*(S) / N, 在I S相近時是最大值，通常是遞增項\n",
    "            ytk = (ytk[0]+dSdt, ytk[1]+dIdt, ytk[2]+dRdt)\n",
    "        if (print_out_details == True): print('接下來七天的確診人數預測（小數後兩位）：', [f\"{num:.2f}\" for num in new_cases_prediction_array_7days])\n",
    "        new_cases_prediction_array = np.append(new_cases_prediction_array, new_cases_prediction_array_7days)\n",
    "\n",
    "    if (print_out_prediction_array == True):\n",
    "        print('去除第0天到第27天，針對第28天以後的預測為（小數後兩位）：\\n', [f\"{num:.2f}\" for num in new_cases_prediction_array])\n",
    "\n",
    "\n",
    "\n",
    "    # 整理預測的ARRAY和實際的ARRAY\n",
    "    ending_point = len(data) - 28\n",
    "    new_cases_prediction_array = new_cases_prediction_array[0:ending_point]\n",
    "    actual_new_cases = data['new_cases_smoothed'].iloc[28:]\n",
    "    actual_new_cases = np.nan_to_num(actual_new_cases, nan=0)  # 去除空值轉成0\n",
    "\n",
    "    # 計算各種指標\n",
    "    mae = mean_absolute_error(actual_new_cases, new_cases_prediction_array)\n",
    "    rmse = np.sqrt(mean_squared_error(actual_new_cases, new_cases_prediction_array))\n",
    "    mape = calculate_mape(actual_new_cases, new_cases_prediction_array)\n",
    "    ppe_value_error, ppe_time_error = calculate_ppe(actual_new_cases, new_cases_prediction_array)\n",
    "\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MAE / Mean: {mae / np.mean(actual_new_cases)}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'MAPE: {mape:.2f}%')\n",
    "    print(f'Peak Prediction Error (Value): {ppe_value_error}')\n",
    "    print(f'Peak Prediction Error (Time): {ppe_time_error} days')\n",
    "\n",
    "    return new_cases_prediction_array, actual_new_cases, mae, (mae / np.mean(actual_new_cases)), rmse, mape, ppe_value_error, ppe_time_error\n",
    "\n",
    "# gamma = 1/10  # assuming that recovering days are 10 days\n",
    "# tuple1 = do_rolling_prediction_by_SIR_and_calculate_indicators(data, print_out_details=False, print_out_prediction_array=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"MYS\", \"ARG\", \"MEX\", \"JPN\", \"CAN\", \"THA\", \"VNM\", \"TWN\", \"CHN\", \"SGP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARG', 'MEX', 'THA', 'TWN', 'CHN', 'MAC', 'KOR', 'JPN', 'USA', 'CAN', 'VNM', 'SGP', 'HKG', 'MYS', 'FRA', 'NPL', 'AUS', 'LKA', 'DEU', 'KHM', 'ARE', 'FIN', 'IND', 'PHL', 'FJI', 'GBR', 'RUS', 'ITA', 'SWE', 'ESP']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'data\\owid-covid-data.csv')\n",
    "# 計算 iso_code 的數量，排除以 \"OWID\" 開頭的代碼\n",
    "filtered_iso_codes = data[\"iso_code\"].value_counts()\n",
    "filtered_iso_codes = filtered_iso_codes[~filtered_iso_codes.index.str.startswith(\"OWID\")]\n",
    "\n",
    "# 取出前 10 至 20 的地區代號並轉換為列表\n",
    "iso_code_list = filtered_iso_codes.iloc[:30].index.tolist()\n",
    "\n",
    "# 顯示結果\n",
    "print(iso_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_regions = [region for region in iso_code_list if region not in regions] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Region: MAC------------------\n",
      "MAE: 0.09468302594979607\n",
      "MAE / Mean: 0.9867086311175226\n",
      "RMSE: 0.31750102651849765\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 1.7819154404603628\n",
      "Peak Prediction Error (Time): 500 days\n",
      "----------------Region: KOR------------------\n",
      "MAE: 1965.7643237186148\n",
      "MAE / Mean: 0.3915166355862464\n",
      "RMSE: 10884.181238270581\n",
      "MAPE: 53.81%\n",
      "Peak Prediction Error (Value): 104376.6810252938\n",
      "Peak Prediction Error (Time): 4 days\n",
      "----------------Region: USA------------------\n",
      "MAE: 33651.31322094367\n",
      "MAE / Mean: 0.3172317253429801\n",
      "RMSE: 98165.62164240067\n",
      "MAPE: inf%\n",
      "Peak Prediction Error (Value): 876620.5665342221\n",
      "Peak Prediction Error (Time): 3 days\n",
      "----------------Region: HKG------------------\n",
      "MAE: 208.58708410751342\n",
      "MAE / Mean: 0.5173197295748287\n",
      "RMSE: 2421.777144219091\n",
      "MAPE: inf%\n",
      "Peak Prediction Error (Value): 50240.37062579234\n",
      "Peak Prediction Error (Time): 1 days\n",
      "----------------Region: FRA------------------\n",
      "MAE: 10520.497229441904\n",
      "MAE / Mean: 0.3432452480338483\n",
      "RMSE: 30203.518361817285\n",
      "MAPE: inf%\n",
      "Peak Prediction Error (Value): 309153.1653984185\n",
      "Peak Prediction Error (Time): 2 days\n",
      "----------------Region: NPL------------------\n",
      "MAE: 974.0691586584209\n",
      "MAE / Mean: 0.7407785997168007\n",
      "RMSE: 3311.398439039636\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 25847.08590941254\n",
      "Peak Prediction Error (Time): 9 days\n",
      "----------------Region: AUS------------------\n",
      "MAE: 5168.901889030331\n",
      "MAE / Mean: 1.3058551848368078\n",
      "RMSE: 28043.8797583111\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 319885.75932278496\n",
      "Peak Prediction Error (Time): 9 days\n",
      "----------------Region: LKA------------------\n",
      "MAE: 285.668414403439\n",
      "MAE / Mean: 0.32690163661906924\n",
      "RMSE: 647.4290448997866\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 2741.687580161748\n",
      "Peak Prediction Error (Time): 6 days\n",
      "----------------Region: DEU------------------\n",
      "MAE: 6749.204540696677\n",
      "MAE / Mean: 0.33600507663145246\n",
      "RMSE: 18349.18679321001\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 175904.9332141067\n",
      "Peak Prediction Error (Time): 1 days\n",
      "----------------Region: KHM------------------\n",
      "MAE: 59.69474850773968\n",
      "MAE / Mean: 0.33767589778603235\n",
      "RMSE: 152.14632730652536\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 1228.976716440869\n",
      "Peak Prediction Error (Time): 58 days\n",
      "----------------Region: ARE------------------\n",
      "MAE: 361.801570784276\n",
      "MAE / Mean: 0.3035083148749484\n",
      "RMSE: 979.4813123743636\n",
      "MAPE: 31.45%\n",
      "Peak Prediction Error (Value): 9493.452433586484\n",
      "Peak Prediction Error (Time): 353 days\n",
      "----------------Region: FIN------------------\n",
      "MAE: 284.7169713652352\n",
      "MAE / Mean: 0.3225980054912611\n",
      "RMSE: 1012.5995017786252\n",
      "MAPE: inf%\n",
      "Peak Prediction Error (Value): 9309.817719315026\n",
      "Peak Prediction Error (Time): 7 days\n",
      "----------------Region: IND------------------\n",
      "MAE: 30325.43532258706\n",
      "MAE / Mean: 0.5211427776052112\n",
      "RMSE: 112788.64161642466\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 1198009.6122560806\n",
      "Peak Prediction Error (Time): 270 days\n",
      "----------------Region: PHL------------------\n",
      "MAE: 3917.108299481051\n",
      "MAE / Mean: 0.789189865519225\n",
      "RMSE: 20802.36889465882\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 301187.1795487709\n",
      "Peak Prediction Error (Time): 8 days\n",
      "----------------Region: FJI------------------\n",
      "MAE: 63.017128869974734\n",
      "MAE / Mean: 0.7272504198183275\n",
      "RMSE: 233.88458704547585\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 1782.4991543891288\n",
      "Peak Prediction Error (Time): 182 days\n",
      "----------------Region: GBR------------------\n",
      "MAE: 7551.0179400454845\n",
      "MAE / Mean: 0.31573041892625175\n",
      "RMSE: 18603.856435116686\n",
      "MAPE: inf%\n",
      "Peak Prediction Error (Value): 136596.1781599866\n",
      "Peak Prediction Error (Time): 8 days\n",
      "----------------Region: RUS------------------\n",
      "MAE: 7359.495305045465\n",
      "MAE / Mean: 0.3318030547398243\n",
      "RMSE: 29078.90526327052\n",
      "MAPE: nan%\n",
      "Peak Prediction Error (Value): 313442.63674509415\n",
      "Peak Prediction Error (Time): 2 days\n",
      "----------------Region: ITA------------------\n",
      "MAE: 7576.502682381589\n",
      "MAE / Mean: 0.43390545770715827\n",
      "RMSE: 26011.85144970348\n",
      "MAPE: inf%\n",
      "Peak Prediction Error (Value): 251820.02577716482\n",
      "Peak Prediction Error (Time): 6 days\n",
      "----------------Region: SWE------------------\n",
      "MAE: 1803.8356259154937\n",
      "MAE / Mean: 0.542426081987158\n",
      "RMSE: 6834.838048172436\n",
      "MAPE: inf%\n",
      "Peak Prediction Error (Value): 68287.76095745363\n",
      "Peak Prediction Error (Time): 7 days\n",
      "----------------Region: ESP------------------\n",
      "MAE: 9172.625173384095\n",
      "MAE / Mean: 0.6178089174265046\n",
      "RMSE: 25667.235596736937\n",
      "MAPE: inf%\n",
      "Peak Prediction Error (Value): 200718.46384739262\n",
      "Peak Prediction Error (Time): 8 days\n"
     ]
    }
   ],
   "source": [
    "# pipelining calculation\n",
    "\n",
    "#initialising\n",
    "population = int(data.iloc[0]['population'])\n",
    "gamma = 1/10  # assuming that recovering days are 10 days\n",
    "original_data = pd.read_csv(r\"data\\owid-covid-data.csv\")\n",
    "\n",
    "output_list = []\n",
    "for region in new_regions:\n",
    "    print(f\"----------------Region: {region}------------------\")\n",
    "    data = original_data[original_data[\"iso_code\"] == region]\n",
    "    data = extract_SIR_target_data(data)\n",
    "    data = data.fillna(0)  # 將空值填上0\n",
    "    tuple1 = do_rolling_prediction_by_SIR_and_calculate_indicators(data, print_out_details=False, print_out_prediction_array=False)\n",
    "    output_list.append([str(region), tuple1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
