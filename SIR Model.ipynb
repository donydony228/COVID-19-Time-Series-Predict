{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import log\n",
    "from matplotlib import pyplot as plt \n",
    "from scipy.integrate import odeint  # 微分用\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 確保項目根目錄在模組路徑中\n",
    "project_root = os.path.abspath(\"COVID-19-TIME-SERIES-PREDICT\")  # 替換為你的根目錄路徑\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# 導入自編模組\n",
    "from utils.common_tools import *\n",
    "\n",
    "# pandas跟NUMPY設定\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AFG' 'OWID_AFR' 'ALB' 'DZA' 'AND' 'AGO' 'AIA' 'ATG' 'ARG' 'ARM' 'ABW'\n",
      " 'OWID_ASI' 'AUS' 'AUT' 'AZE' 'BHS' 'BHR' 'BGD' 'BRB' 'BLR' 'BEL' 'BLZ'\n",
      " 'BEN' 'BMU' 'BTN' 'BOL' 'BES' 'BIH' 'BWA' 'BRA' 'VGB' 'BRN' 'BGR' 'BFA'\n",
      " 'BDI' 'KHM' 'CMR' 'CAN' 'CPV' 'CYM' 'CAF' 'TCD' 'CHL' 'CHN' 'COL' 'COM'\n",
      " 'COG' 'COK' 'CRI' 'CIV' 'HRV' 'CUB' 'CUW' 'CYP' 'CZE' 'COD' 'DNK' 'DJI'\n",
      " 'DMA' 'DOM' 'ECU' 'EGY' 'SLV' 'GNQ' 'ERI' 'EST' 'SWZ' 'ETH' 'OWID_EUR'\n",
      " 'OWID_EUN' 'FRO' 'FLK' 'FJI' 'FIN' 'FRA' 'PYF' 'GAB' 'GMB' 'GEO' 'DEU'\n",
      " 'GHA' 'GIB' 'GRC' 'GRL' 'GRD' 'GTM' 'GGY' 'GIN' 'GNB' 'GUY' 'HTI'\n",
      " 'OWID_HIC' 'HND' 'HKG' 'HUN' 'ISL' 'IND' 'IDN' 'OWID_INT' 'IRN' 'IRQ'\n",
      " 'IRL' 'IMN' 'ISR' 'ITA' 'JAM' 'JPN' 'JEY' 'JOR' 'KAZ' 'KEN' 'KIR'\n",
      " 'OWID_KOS' 'KWT' 'KGZ' 'LAO' 'LVA' 'LBN' 'LSO' 'LBR' 'LBY' 'LIE' 'LTU'\n",
      " 'OWID_LIC' 'OWID_LMC' 'LUX' 'MAC' 'MDG' 'MWI' 'MYS' 'MDV' 'MLI' 'MLT'\n",
      " 'MHL' 'MRT' 'MUS' 'MEX' 'FSM' 'MDA' 'MCO' 'MNG' 'MNE' 'MSR' 'MAR' 'MOZ'\n",
      " 'MMR' 'NAM' 'NRU' 'NPL' 'NLD' 'NCL' 'NZL' 'NIC' 'NER' 'NGA' 'NIU'\n",
      " 'OWID_NAM' 'MKD' 'OWID_CYN' 'NOR' 'OWID_OCE' 'OMN' 'PAK' 'PLW' 'PSE'\n",
      " 'PAN' 'PNG' 'PRY' 'PER' 'PHL' 'PCN' 'POL' 'PRT' 'QAT' 'ROU' 'RUS' 'RWA'\n",
      " 'SHN' 'KNA' 'LCA' 'SPM' 'VCT' 'WSM' 'SMR' 'STP' 'SAU' 'SEN' 'SRB' 'SYC'\n",
      " 'SLE' 'SGP' 'SXM' 'SVK' 'SVN' 'SLB' 'SOM' 'ZAF' 'OWID_SAM' 'KOR' 'SSD'\n",
      " 'ESP' 'LKA' 'SDN' 'SUR' 'SWE' 'CHE' 'SYR' 'TWN' 'TJK' 'TZA' 'THA' 'TLS'\n",
      " 'TGO' 'TKL' 'TON' 'TTO' 'TUN' 'TUR' 'TKM' 'TCA' 'TUV' 'UGA' 'UKR' 'ARE'\n",
      " 'GBR' 'USA' 'OWID_UMC' 'URY' 'UZB' 'VUT' 'VAT' 'VEN' 'VNM' 'WLF'\n",
      " 'OWID_WRL' 'YEM' 'ZMB' 'ZWE']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-02-24         5.00       5.00   \n",
       "1      AFG      Asia  Afghanistan  2020-02-25         5.00       0.00   \n",
       "2      AFG      Asia  Afghanistan  2020-02-26         5.00       0.00   \n",
       "3      AFG      Asia  Afghanistan  2020-02-27         5.00       0.00   \n",
       "4      AFG      Asia  Afghanistan  2020-02-28         5.00       0.00   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "1                 NaN           NaN         NaN                  NaN  ...   \n",
       "2                 NaN           NaN         NaN                  NaN  ...   \n",
       "3                 NaN           NaN         NaN                  NaN  ...   \n",
       "4                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                   37.75   \n",
       "1             NaN           NaN                   37.75   \n",
       "2             NaN           NaN                   37.75   \n",
       "3             NaN           NaN                   37.75   \n",
       "4             NaN           NaN                   37.75   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                        0.50            64.83                     0.51   \n",
       "1                        0.50            64.83                     0.51   \n",
       "2                        0.50            64.83                     0.51   \n",
       "3                        0.50            64.83                     0.51   \n",
       "4                        0.50            64.83                     0.51   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "1               NaN                                      NaN  \n",
       "2               NaN                                      NaN  \n",
       "3               NaN                                      NaN  \n",
       "4               NaN                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_covid_data()  # -> pd.DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39835428.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  total_cases  new_cases  new_deaths  population\n",
       "0  2020-02-24         5.00       5.00         NaN 39835428.00\n",
       "1  2020-02-25         5.00       0.00         NaN 39835428.00\n",
       "2  2020-02-26         5.00       0.00         NaN 39835428.00\n",
       "3  2020-02-27         5.00       0.00         NaN 39835428.00\n",
       "4  2020-02-28         5.00       0.00         NaN 39835428.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = extract_SIR_target_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we've got functions here\n",
    "\n",
    "def dAdt(Y, t, N, beta, gamma) -> list:\n",
    "    # 三條函式\n",
    "    # the t argument in the deriv function is technically not redundant, even though it is not directly used in the function\n",
    "    '''\n",
    "    Calculate the changing of the three subgroups.\n",
    "    A: S, I, R\n",
    "    t: time\n",
    "    beta: tesla(average persons interacted) * c(infectious rate)\n",
    "    gamma: recovery rate (=1/d)\n",
    "    N: total population, assumed S+I+R = N\n",
    "    '''\n",
    "    S, I, R = Y\n",
    "    dSdt = -(beta)*(I)*(S) / N\n",
    "    dIdt = (beta)*(I)*(S) / N - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt\n",
    "\n",
    "'''INITIAL STATUS: A = [N - I0, I0, 0]'''\n",
    "\n",
    "\n",
    "def log_transform(data: pd.DataFrame, column: str):\n",
    "    data[\"log_\" + column] = log(data[column] + 0.01)\n",
    "    return data\n",
    "\n",
    "def adf_test(data: pd.DataFrame, column: str):\n",
    "    data.dropna(inplace=True)\n",
    "    result = adfuller(data[column])\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if result[1] < 0.05:\n",
    "        print(\"數據是穩態的\")\n",
    "    else:\n",
    "        print(\"數據是非穩態的，需要進行差分\")\n",
    "\n",
    "    # 3. 繪製 ACF 和 PACF 檢查自相關性\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_acf(data[\"new_cases\"], lags=30, ax=plt.subplot(121))\n",
    "    plot_pacf(data[\"new_cases\"], lags=30, ax=plt.subplot(122))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def grid_search_ARIMA(data: pd.DataFrame, column: str):\n",
    "    best_model = None\n",
    "    best_order = None\n",
    "    best_aic = float(\"inf\")\n",
    "\n",
    "    for p in range(3):\n",
    "        for d in range(3):\n",
    "            for q in range(3):\n",
    "                try:\n",
    "                    model = ARIMA(data[column], order=(p, d, q))\n",
    "                    model_fit = model.fit()\n",
    "\n",
    "                    if model_fit.aic < best_aic:\n",
    "                        best_model = model_fit\n",
    "                        best_order = (p, d, q)\n",
    "                        best_aic = model_fit.aic\n",
    "                except Exception as e:\n",
    "                    # 捕捉錯誤，但繼續進行其他組合的測試\n",
    "                    print(f\"Error for order ({p}, {d}, {q}): {e}\")\n",
    "                    continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"Best Model Summary:\")\n",
    "        print(best_model.summary())\n",
    "    else:\n",
    "        print(\"No suitable model found.\")\n",
    "\n",
    "    return best_order\n",
    "\n",
    "def rolling_forecast(data: pd.DataFrame, column: str, best_order: tuple):\n",
    "    # 劃分數據集\n",
    "    train_size = int(len(data) * 0.8 // 1)  # 使用前 80% 的數據作為訓練集\n",
    "    train = data.iloc[:train_size]     # 訓練集\n",
    "    test = data.iloc[train_size:]      # 測試集\n",
    "\n",
    "    print(f\"Train Size: {len(train)}, Test Size: {len(test)}\")\n",
    "\n",
    "    # 初始化滾動預測\n",
    "    history = [x for x in train[column]]  # 使用訓練集的初始數據\n",
    "    predictions = []  # 儲存每次的預測結果\n",
    "\n",
    "    # 滾動預測\n",
    "    for t in range(len(test)):\n",
    "        # 構建並擬合 ARIMA 模型\n",
    "        model = ARIMA(history, order=best_order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # 預測下一個時間點\n",
    "        yhat = model_fit.forecast(steps=1)[0]\n",
    "        predictions.append(yhat)\n",
    "\n",
    "        # 將真實值加入訓練集\n",
    "        history.append(test[column].iloc[t])\n",
    "\n",
    "    # 計算各種指標\n",
    "    mae = mean_absolute_error(test[column], predictions)\n",
    "    r2 = r2_score(test[column], predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(test[column], predictions))\n",
    "\n",
    "    print(f\"Mean of Real Data: {np.mean(test[column])}\")\n",
    "    print(f\"Median of Real Data: {np.median(test[column])}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\") # 平均絕對誤差\n",
    "    print(f\"Percentage of MAE: {mae / np.mean(test[column])}\") # 平均絕對誤差占比\n",
    "    print(f\"Rolling Forecast RMSE: {rmse}\") # RMSE\n",
    "\n",
    "def check_residuals(data: pd.DataFrame, column: str, best_order: tuple):\n",
    "    # 檢查殘差的自相關性\n",
    "    model = ARIMA(data[column], order=best_order)\n",
    "    model_fit = model.fit()\n",
    "    residuals = model_fit.resid\n",
    "    lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)\n",
    "    print(lb_test)\n",
    "\n",
    "    # 檢查殘差的正態分佈\n",
    "    stat, p = normaltest(residuals)\n",
    "    print(f\"Normality Test: Statistic={stat}, p={p}\")\n",
    "    if p > 0.05:\n",
    "        print(\"殘差接近正態分佈\")\n",
    "    else:\n",
    "        print(\"殘差偏離正態分佈\")\n",
    "\n",
    "def multi_step_forecast(data: pd.DataFrame, column: str, best_order: tuple, forecast_steps: int):\n",
    "    # 劃分數據集\n",
    "    train_size = int(len(data) * 0.8 // 1)  # 使用前 80% 的數據作為訓練集\n",
    "    train = data.iloc[:train_size]     # 訓練集\n",
    "    test = data.iloc[train_size:]      # 測試集\n",
    "    \n",
    "    \n",
    "    model = ARIMA(data[column], order=best_order)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    forecast = model_fit.forecast(steps=forecast_steps)\n",
    "\n",
    "    # 比較真實值與預測值\n",
    "    real_values = test[\"new_cases\"].iloc[:forecast_steps]\n",
    "    rmse = np.sqrt(mean_squared_error(real_values, forecast))\n",
    "    print(f\"Multi-step Forecast RMSE: {rmse}\")\n",
    "\n",
    "def pipeline(data: pd.DataFrame, column: str, forecast_steps: int):\n",
    "    data = log_transform(data, column)\n",
    "    adf_test(data, \"log_\" + column)\n",
    "    print(\"----------------Gird Search ARIMA------------------\")\n",
    "    best_order = grid_search_ARIMA(data, \"log_\" + column)\n",
    "    print(\"----------------Rolling Forecast------------------\")\n",
    "    rolling_forecast(data, \"log_\" + column, best_order)\n",
    "    print(\"----------------Check Residuals------------------\")\n",
    "    check_residuals(data, \"log_\" + column, best_order)\n",
    "    print(\"----------------Multi-step Forecast------------------\")\n",
    "    multi_step_forecast(data, \"log_\" + column, best_order, forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39835423, 5, 0)\n",
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "      ... \n",
      "587    587\n",
      "588    588\n",
      "589    589\n",
      "590    590\n",
      "591    591\n",
      "Name: date, Length: 592, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "[[39835423.          5.          0.  ]\n",
      " [39835421.95        5.53        0.53]\n",
      " [39835420.79        6.11        1.11]\n",
      " ...\n",
      " [ 8094074.1         0.   31741353.9 ]\n",
      " [ 8094074.1         0.   31741353.9 ]\n",
      " [ 8094074.1         0.   31741353.9 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ny0 = S0, I0, R0\\n# Integrate the SIR equations over the time grid, t.\\nret = odeint(deriv, y0, t, args=(N, beta, gamma))\\nS, I, R = ret.T'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialising\n",
    "gamma = 1/10  # assuming that recovering days are 10 days\n",
    "cutting_point = 0.8\n",
    "split_index = int(len(data) * 0.8)\n",
    "training_data = data.iloc[:split_index]\n",
    "\n",
    "# finding the most suiting beta by trying different betas and also comparing the MAEs\n",
    "population = int(training_data.iloc[0]['population'])\n",
    "initial_cases = int(training_data.iloc[0]['total_cases'])\n",
    "S0 = int(population - initial_cases)\n",
    "I0 = int(initial_cases)\n",
    "R0 = 0\n",
    "y0 = (S0, I0, R0)\n",
    "\n",
    "training_data['date'] = pd.to_datetime(training_data['date'])\n",
    "t = (training_data['date'] - training_data['date'].iloc[0]).dt.days  # Calculate the numeric time points (days since the first date)\n",
    "\n",
    "print(y0)\n",
    "print(t)\n",
    "print(type(t))\n",
    "\n",
    "\n",
    "beta = 0.2\n",
    "S_I_R_series = odeint(dAdt, y0, t, args=(population, beta, gamma))\n",
    "# ordinary differential equation integration; odeint的三個arguments: 方程式、Y、Xi\n",
    "# t is a numeric series, which is necessary for odeint\n",
    "S, I, R = S_I_R_series.T\n",
    "\n",
    "print(S_I_R_series)\n",
    "print(S)\n",
    "print(I)\n",
    "print(R)\n",
    "'''\n",
    "y0 = S0, I0, R0\n",
    "# Integrate the SIR equations over the time grid, t.\n",
    "ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n",
    "S, I, R = ret.T'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    \"ARG\",\n",
    "    \"MEX\",\n",
    "    \"THA\",\n",
    "    \"TWN\",\n",
    "    \"CHN\",\n",
    "    \"OWID_ASI\",\n",
    "    \"OWID_NAM\",\n",
    "    \"MAC\",\n",
    "    \"KOR\",\n",
    "    \"OWID_UMC\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regionss:\n",
    "    print(f\"----------------Region: {region}------------------\")\n",
    "    data = pd.read_csv(r\"data\\owid-covid-data.csv\")\n",
    "    data = data[data[\"iso_code\"] == region]\n",
    "    data = data[[\"date\", \"new_cases\"]]\n",
    "    pipeline(data, \"new_cases\", 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
